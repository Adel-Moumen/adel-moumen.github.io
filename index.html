<!DOCTYPE html>
<html dir="ltr" lang="en-US">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Adel Moumen</title>
<meta name="description" content="Adel Moumen — Speech & Language Modelling, SpeechBrain, multilingual SLMs"/>
<link rel="stylesheet" href="styles.css" />
  <link rel="icon" href="assets/favicon.svg" type="image/svg+xml" />
</head>
<body>
<div id="body-container">
  <div id="header">
    <h1 id="site-title"><a href="#" rel="home"><span>Adel Moumen</span></a></h1>
    <h2 id="site-description"><span>PhD student in engineering</span></h2>
  </div>

  <div id="content">
    <div id="columns-wrap">
      <!-- LEFT COLUMN -->
      <div id="col-left" class="column">
        <p><a href="#"><img class="alignleft" src="assets/pp-2025.jpeg" alt="Adel Moumen portrait" width="206" /></a></p>
        <!-- <p><a href="#" target="_blank" rel="noopener noreferrer">CV</a> and <a href="#bio">BIO</a></p> -->
        <p>University of Cambridge<br/>
        Department of Engineering<br/>
        Cambridge, UK</p>
        <p style="text-align: left;">
          <a href="https://github.com/Adel-Moumen" rel="noopener">GitHub</a><br>
          <a href="https://scholar.google.com/citations?user=SOks-o4AAAAJ&hl=en" rel="noopener">Google Scholar</a><br>
          <a href="https://www.linkedin.com/in/adel-moumen/" rel="noopener">LinkedIn</a>
        </p>
        <p>am3303 [at] cam.ac.uk</p>
      </div>

      <!-- RIGHT COLUMN -->
      <div id="col-right" class="column">
        <p id="bio"><strong class="section">ABOUT ME</strong></p>
        <p>
          I am a 23-year-old PHD student at the University of Cambridge under the supervision of Prof. Phil Woodland. I completed my Bachelor's and Master's degree 
          in computer science and AI with distinction in an innovation and research-devoted <a href="https://reseau-figure.fr/about-cmi/?lang=en">curriculum</a> and earned a two-year entrepreneurship diploma in 2022. I am professionally also contributing to the development of <a href="https://speechbrain.github.io">SpeechBrain</a>, an all-in-one, open-source, PyTorch-based speech processing toolkit with more than 10,000+ stars on GitHub. At SpeechBrain, I lead the core efforts of the toolkit. In 2019, I started as an autodidact on deep learning and helped frame the largest French AI community.

        </p>

        <p class="notice-red"><em>Actively seeking a research internship for Summer 2026.</em></p>

        <p><strong class="section">RESEARCH INTERESTS</strong></p>
        <p>
        I develop multilingual Speech Language Models (SLMs) that speak natively, focusing on cross-lingual and cross-modal transfer. My work spans discrete speech tokenisers, novel architectures, and training curricula with the aim of solving the "Speech Turing Test".
  
        </p>

        <p><strong class="section">SPEECHBRAIN</strong></p>
        <p>
          I serve as a core maintainer of the SpeechBrain toolkit, responsible for its core development and overall management. My role entails actively supporting the toolkit by engaging in discussions, addressing issues, and reviewing pull requests. Additionally, I focus on expanding the toolkit’s capabilities by introducing new features for automatic speech recognition.
          </p>
  
          <p>
          One of my notable contributions was integrating the openAI’s Whisper model. My ongoing work involves incorporating advanced decoding methods into SpeechBrain speech recognition systems. It includes integrating CTC frame-synchronous beam search and CTC/Att joint decoding, leveraging language models such as kenLM and TransformerLM (e.g., GPT2) for improved performance. I am also working on the integration of Speech LLMs within SpeechBrain.
          </p>

        <p><strong class="section">PUBLICATIONS</strong></p>
        <ul>
          <li>Cross‑Lingual Interleaving for Spoken Language Models. <em>ICASSP 2026</em> (under review).</li>
          <li>Text-speech language models with improved cross-modal transfer by aligning abstraction levels. Preprint. [<a href="https://arxiv.org/pdf/2503.06211">preprint</a>]</li>
          <li>Discrete Audio Tokens: More Than a Survey! <em>TMLR</em> [<a href="https://arxiv.org/pdf/2506.10274?">preprint</a>]</li>
          <li>Open-source conversational ai with speechbrain 1.0. <em>JMLR 2024</em> [<a href="https://www.jmlr.org/papers/volume25/24-0991/24-0991.pdf">preprint</a>]</li>
          <li>Stabilising and accelerating light gated recurrent units for automatic speech recognition. <em>ICASSP 2023</em> [<a href="https://arxiv.org/pdf/2302.10144">preprint</a>]</li>
        </ul>

        <p class="muted">For a more complete list: <a href="https://scholar.google.com/citations?user=SOks-o4AAAAJ&hl=en">Google Scholar</a>.</p>

      </div>
      <div class="clearfix"></div>
    </div>
  </div>
</div>
</body>
</html>
